{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Identifying Fraud from Enron Emails and Financial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In 2000, Enron was one of the largest companies in the United States. By 2002, it had collapsed into bankruptcy due to widespread corporate fraud. In the resulting Federal investigation, there was a significant amount of typically confidential information entered into the public record, including tens of thousands of emails and detailed financial data for to executives.\n",
    "\n",
    "Using the EDA skill and machine learning skill, I'll build a classifier to identifying fraud from enron emails and financial data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File of this project\n",
    "\n",
    "* `final_project/modelpipeline.py` : script I wrote before the final script to include a whole process of data preprocessing, generating new features, spliting into training and testing set, feature scale, feature selection, evaluating 8 different classifiers.\n",
    "\n",
    "\n",
    "* `final_project/poi_id.py` : The final script to use the selected features to build a classifier, do parameter tuning and return the required pickle files (my_dataset.pkl, my_classifier.pkl, my_feature_list.pkl).\n",
    "\n",
    "\n",
    "* `final_project/my_classifier.pkl`\n",
    "\n",
    "\n",
    "* `final_project/my_dataset.pkl`\n",
    "\n",
    "\n",
    "* `final_project/my_feature_list.pkl`\n",
    "\n",
    "\n",
    "* `final_project/final_project_dataset.pkl` : Final project dataset.\n",
    "\n",
    "\n",
    "* `final_project/data.csv` : A csv formate dataset transformed from `final_project_dataset.pkl`\n",
    "\n",
    "\n",
    "* `final_project/Project.html` : Documentation of the work I've done and answers to the questions.\n",
    "\n",
    "\n",
    "* `final_project/tester.py` : Script for evaluation.\n",
    "\n",
    "\n",
    "* `final_project/transformData.py` : Script for transforming data from pkl to csv.\n",
    "\n",
    "\n",
    "* `final_project/modelselect.txt` : Model evaluation result and final features generated from `final_project/modelpipeline.py`.\n",
    "\n",
    "\n",
    "* `tools/` : helper tools and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free-Response Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "> Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those?  [relevant rubric items: “data exploration”, “outlier investigation”]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project is to use financial and email data from Enron to identify whether an individual could be considered a \"person of interest\" (POI). This is a typical classification problem and several  machine learning algorithms as classifier can be used for this problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (146, 21)\n",
      "Allocation across classes (POI/non-POI):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    128\n",
       "True      18\n",
       "Name: poi, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df = pd.read_csv('data.csv',index_col=[0])\n",
    "print(\"data shape:\",df.shape)\n",
    "print(\"Allocation across classes (POI/non-POI):\")\n",
    "df['poi'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>email_address</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>poi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>365788.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1061827.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark.metts@enron.com</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>267102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10623258.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>170941.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211725.0</td>\n",
       "      <td>4890344.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>1788391.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6678735.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12961.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-400729.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>steven.elliott@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>NaN</td>\n",
       "      <td>764.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>651850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386335.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1038185.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bill.cordes@enron.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>243293.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288682.0</td>\n",
       "      <td>5538001.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>853064.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6391065.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>11350.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3117011.0</td>\n",
       "      <td>1617011.0</td>\n",
       "      <td>kevin.hannon@enron.com</td>\n",
       "      <td>32.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    salary  to_messages  deferral_payments  total_payments  \\\n",
       "name                                                                         \n",
       "METTS MARK        365788.0        807.0                NaN       1061827.0   \n",
       "BAXTER JOHN C     267102.0          NaN          1295738.0       5634343.0   \n",
       "ELLIOTT STEVEN    170941.0          NaN                NaN        211725.0   \n",
       "CORDES WILLIAM R       NaN        764.0                NaN             NaN   \n",
       "HANNON KEVIN P    243293.0       1045.0                NaN        288682.0   \n",
       "\n",
       "                  exercised_stock_options      bonus  restricted_stock  \\\n",
       "name                                                                     \n",
       "METTS MARK                            NaN   600000.0          585062.0   \n",
       "BAXTER JOHN C                   6680544.0  1200000.0         3942714.0   \n",
       "ELLIOTT STEVEN                  4890344.0   350000.0         1788391.0   \n",
       "CORDES WILLIAM R                 651850.0        NaN          386335.0   \n",
       "HANNON KEVIN P                  5538001.0  1500000.0          853064.0   \n",
       "\n",
       "                  shared_receipt_with_poi  restricted_stock_deferred  \\\n",
       "name                                                                   \n",
       "METTS MARK                          702.0                        NaN   \n",
       "BAXTER JOHN C                         NaN                        NaN   \n",
       "ELLIOTT STEVEN                        NaN                        NaN   \n",
       "CORDES WILLIAM R                     58.0                        NaN   \n",
       "HANNON KEVIN P                     1035.0                        NaN   \n",
       "\n",
       "                  total_stock_value  ...    loan_advances  from_messages  \\\n",
       "name                                 ...                                   \n",
       "METTS MARK                 585062.0  ...              NaN           29.0   \n",
       "BAXTER JOHN C            10623258.0  ...              NaN            NaN   \n",
       "ELLIOTT STEVEN            6678735.0  ...              NaN            NaN   \n",
       "CORDES WILLIAM R          1038185.0  ...              NaN           12.0   \n",
       "HANNON KEVIN P            6391065.0  ...              NaN           32.0   \n",
       "\n",
       "                      other  from_this_person_to_poi  director_fees  \\\n",
       "name                                                                  \n",
       "METTS MARK           1740.0                      1.0            NaN   \n",
       "BAXTER JOHN C     2660303.0                      NaN            NaN   \n",
       "ELLIOTT STEVEN      12961.0                      NaN            NaN   \n",
       "CORDES WILLIAM R        NaN                      0.0            NaN   \n",
       "HANNON KEVIN P      11350.0                     21.0            NaN   \n",
       "\n",
       "                  deferred_income  long_term_incentive  \\\n",
       "name                                                     \n",
       "METTS MARK                    NaN                  NaN   \n",
       "BAXTER JOHN C          -1386055.0            1586055.0   \n",
       "ELLIOTT STEVEN          -400729.0                  NaN   \n",
       "CORDES WILLIAM R              NaN                  NaN   \n",
       "HANNON KEVIN P         -3117011.0            1617011.0   \n",
       "\n",
       "                             email_address from_poi_to_this_person    poi  \n",
       "name                                                                       \n",
       "METTS MARK            mark.metts@enron.com                    38.0  False  \n",
       "BAXTER JOHN C                          NaN                     NaN  False  \n",
       "ELLIOTT STEVEN    steven.elliott@enron.com                     NaN  False  \n",
       "CORDES WILLIAM R     bill.cordes@enron.com                    10.0  False  \n",
       "HANNON KEVIN P      kevin.hannon@enron.com                    32.0   True  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a glance at the data, it contains 146 records with 20 features and 1 label. And after reading the feature names, I identified 14 financial features and 6 email features. Although it has missing data, the data structure is quite clear and can be fed into classifiers to train and test furture data for whether or not their label of poi is 'True' or 'False'. The summary of the \"poi\" class also indicates that this is a biased data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary                        51\n",
       "to_messages                   60\n",
       "deferral_payments            107\n",
       "total_payments                21\n",
       "exercised_stock_options       44\n",
       "bonus                         64\n",
       "restricted_stock              36\n",
       "shared_receipt_with_poi       60\n",
       "restricted_stock_deferred    128\n",
       "total_stock_value             20\n",
       "expenses                      51\n",
       "loan_advances                142\n",
       "from_messages                 60\n",
       "other                         53\n",
       "from_this_person_to_poi       60\n",
       "director_fees                129\n",
       "deferred_income               97\n",
       "long_term_incentive           80\n",
       "email_address                 35\n",
       "from_poi_to_this_person       60\n",
       "poi                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count missing data in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the statistical overview shows, all the features contain missing data, especially loan_advances. It only has 4 validated data point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEZCAYAAAC5AHPcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM8vEAWJmZpk4QMzMLBMHiJmZZfL/AQMrdUnHVP7OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106c50a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "subdf = df[['salary','bonus']]\n",
    "subdf = subdf.dropna()\n",
    "plt.scatter(subdf['salary'],subdf['bonus'])\n",
    "plt.xlabel('salary')\n",
    "plt.ylabel('bonus')\n",
    "plt.title('salary vs bonus')\n",
    "plt.show()\n",
    "print(df['salary'].idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the scatter shows, there's a outlier. This is a spreadsheet artifact and is removed and not considered for further study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "> What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values.  [relevant rubric items: “create new features”, “properly scale features”, “intelligently select feature”]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the \"email_address\" is not numeric feature, I dropped it. And additionally, I created four aggregate features:\n",
    "\n",
    "* `poi_connect`: Sum of `from_poi_to_this_person` and `from_this_person_to_poi`. This indicates how offen this person contacts POIs by email.\n",
    "* `ratio_from_poi`: Fraction of emails the pserson received from POIs.\n",
    "* `ratio_to_poi`: Fraction of emails the pserson send to POIs.\n",
    "* `ratio_poi_connect`: The ratio of `from_poi_to_this_person` and `from_this_person_to_poi`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the above features can be found in the script *modelpipeline.py*. But after I combine these 4 features with other 19 features ('salary', 'to_messages', 'deferral_payments', 'total_payments','exercised_stock_options', 'bonus', 'restricted_stock','shared_receipt_with_poi', 'restricted_stock_deferred','total_stock_value', 'expenses','other', 'from_this_person_to_poi', 'director_fees','deferred_income', 'long_term_incentive','from_poi_to_this_person') and did a feautre selection using *SelectKBest(k=5)*, 4 new features were not in the returned list. So the features I end up using in my POI identifier is 'salary','exercised_stock_options','bonus','shared_receipt_with_poi' and 'total_stock_value', all of which are selected by sklearn function SelectKBest. \n",
    "\n",
    "The score of each feature is listed below. Given that there are only 146 person in the dataset, too many features may lead to overfitting. In this case, 5 top scored features were used in the final model. Because I first tried top 10 and 8 features for the final model, but their precision and recall were quite low, maybe the 10 or 8 features are still too many that can cause overfitting, so finally I only used 5 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature** | **Score**\n",
    "----------- | ---------\n",
    "bonus | 30.65\n",
    "salary | 15.81\n",
    "total_stock_value | 10.81\n",
    "shared_receipt_with_poi | 10.67\n",
    "exercised_stock_options | 9.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final feature list, 4 of them are financial features. The feature on the top is \"bonus\". It gains far more score than other features. It captured how much wealth a person has and it seems that wealth strongly implied whether or not a person is a POI. \"shared_receipt_with_poi\" is the only one email features that indicates person's connection with a POI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the classifiers, features were scaled using MinMaxScaler in sklearn. It even goes before feature selection. Because features should be transformed to a same scale before them are sorted using scoring function or fed into classifiers. since we don't have a favourite one, them should be weighted evenly.\n",
    "\n",
    "For 8 classifiers that I used, k-Nearest Neighbors, Linear SVM and RBF SVM require feature scaling, others don't need it. But since my purpose is only to select a final classifier and for coding convince I used scaled features for all of them. For the final script *poi_id.py*, I didn't use feature scaling as I only use Decision Tree as my final classifier which don't need feature scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "> What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier comparison process can be found in the script *modelpipeline.py*. The script output the comparison result to a file named *modelselect.txt*. I tested 8 classifiers: k-Nearest Neighbors, Linear SVM, RBF SVM, Decision Tree, Random Forest, AdaBoost, Naive Bayes and GradientBoostingClassifier. \n",
    "\n",
    "From the classification report, I found that several classifiers have pretty good result. Because their precision and recall for POI class is higher than 0.3. Since identifying POI is our main task, the performace for the non-POI is less important than that for the POI class. Two SVM performed quite bad. Their precision and recall for POI class is 0. That means they cannot correactlly identify any POI. Random Forest has a perfect overall performance. Decision tree, gradientBoostingClassifier and Naive Bayes are all pretty good.\n",
    "\n",
    "Although Random Forest seems to be the best one, Naive Bayes is the second one. I tried them in the final *poi_id.py*, the result is not good.  So I made a choice between decision tree and gradientBoostingClassifier. Of course gradientBoostingClassifier is a great classifier. But I think decision tree is reasonably sufficient enought for this project and will consume much less time for parameter tuning than gradientBoostingClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report:**\n",
    "\n",
    "Nearest Neighbors:\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.90      0.97      0.94        39\n",
    "        1.0       0.50      0.20      0.29         5\n",
    "\n",
    "    avg / total   0.86      0.89      0.86        44\n",
    "\n",
    "Linear SVM:\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.89      1.00      0.94        39\n",
    "        1.0       0.00      0.00      0.00         5\n",
    "\n",
    "    avg / total   0.79      0.89      0.83        44\n",
    "\n",
    "RBF SVM:\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.89      1.00      0.94        39\n",
    "        1.0       0.00      0.00      0.00         5\n",
    "\n",
    "    avg / total   0.79      0.89      0.83        44\n",
    "\n",
    "Decision Tree:\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.92      0.90      0.91        39\n",
    "        1.0       0.33      0.40      0.36         5\n",
    "\n",
    "    avg / total   0.85      0.84      0.85        44\n",
    "\n",
    "Random Forest:\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.93      1.00      0.96        39\n",
    "        1.0       1.00      0.40      0.57         5\n",
    "\n",
    "    avg / total   0.94      0.93      0.92        44\n",
    "\n",
    "AdaBoost:\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.90      0.90      0.90        39\n",
    "        1.0       0.20      0.20      0.20         5\n",
    "\n",
    "    avg / total   0.82      0.82      0.82        44\n",
    "\n",
    "Naive Bayes:\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.95      0.95      0.95        39\n",
    "        1.0       0.60      0.60      0.60         5\n",
    "\n",
    "    avg / total   0.91      0.91      0.91        44\n",
    "\n",
    "GradientBoostingClassifier:\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.92      0.90      0.91        39\n",
    "        1.0       0.33      0.40      0.36         5\n",
    "\n",
    "    avg / total   0.85      0.84      0.85        44\n",
    "\n",
    "GridSearchCV  DecisionTreeClassifier:\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.92      0.92      0.92        39\n",
    "        1.0       0.40      0.40      0.40         5\n",
    "\n",
    "    avg / total   0.86      0.86      0.86        44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "> What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well?  How did you tune the parameters of your particular algorithm? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For decision tree classifier, parameter tuning is a crucial step to descrese the chance of overfitting. Large max_depth, small min_samples_split and small min_samples_leaf may all lead to overfitting. And whether using gini or  entropy as criterion will affact the quality of a split. I used GridSearchCV as parameter tuning tool and used f1 as scoring function because my goal is to have a classifier with high overall performace of precision and recall. Finally got max_depth=None, min_samples_split=2, min_samples_leaf=1, criterion='gini' for our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 \n",
    "\n",
    "> What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-fold cross-validation is used for parameter tuning. It's fed into GridSearchCV as a parameter \"cv\".\n",
    "\n",
    "A classic prediction mistake is overfitting. It means learning the parameters of a prediction function and testing it on the same data. A model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. When the data set is small, it will also generally turn out that the model does not fit the validation data as well as it fits the training data.\n",
    "\n",
    "So, using the whole dataset for parameter tuning is not right. As our dataset is quite small, simply splitting it into two sets for parameter tuning is not appropriate. As a result, we need cross-validation for parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "> Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several evaluation metrics were computed for the testset. Using classification_report, precision, recall and f1-score for each class is calculated. And also the Matthews correlation coefficient is listed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV  DecisionTreeClassifier:\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.92      0.90      0.91        39\n",
    "        1.0       0.33      0.40      0.36         5\n",
    "\n",
    "    avg / total   0.85      0.84      0.85        44\n",
    "\n",
    "MCC = 0.275070023392"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree I optimized has a very decent precision and recall. Precision can be thought of as the ratio of how often the model is actually correct in identifying a positive label to the total times it guesses a positive label. A higher precision score would mean less false positives. Recall can be thought of as the ratio of how often the model correctly identifies a label as positive to how many total positive labels there actually are. A higher recall score would mean less false negatives. \n",
    "\n",
    "In this project, precision means the ratio of how often my model can correctly identify a person as POI to the total times that it predict a person as POI. On the other hand, recall means the ratio of how often my model can correctly identify a person as POI to all the POIs in the dataset. The Matthews correlation coefficient is used in machine learning as a measure of the quality of binary (two-class) classifications. It takes into account true and false positives and negatives and is generally regarded as a balanced measure which can be used even if the classes are of very different sizes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, I went through the whole steps of machine learning from dataset and questions to finally building, validating and evaluating a model. Future work may involve adding more features and data and further feature engineering. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
